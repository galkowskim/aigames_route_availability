{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/statuses/train_data.csv')\n",
    "df2 = pd.read_csv('data/statuses/val_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from math import sqrt\n",
    "import pandas as pd\n",
    "\n",
    "BOUNDARIES = [(21.9430, -67.5), (55.7765, -135)]\n",
    "VIL_THRESHOLD_COLORS = [\n",
    "    (10000, (0.63, 0.0, 0.01, 1.0)),\n",
    "    (32.32, (0.87, 0.56, 0.0, 1.0)),\n",
    "    (12.16, (0.95, 0.75, 0.0, 1.0)),\n",
    "    (7.08, (0.93, 0.95, 0.0, 1.0)),\n",
    "    (3.53, (0.38, 0.69, 0.0, 1.0)),\n",
    "    (0.77, (0.63, 0.94, 0.0, 1.0)),\n",
    "    (0.52, (0.9, 0.9, 0.9, 0.03)),\n",
    "]\n",
    "\n",
    "\n",
    "def matrix_to_weather_colormap(sparse_matrix: sparse.csr_matrix) -> np.ndarray:\n",
    "    matrix = sparse_matrix.toarray()\n",
    "    result = np.zeros(shape=matrix.shape + (4,))\n",
    "    for thresh, color in VIL_THRESHOLD_COLORS:\n",
    "        result[matrix <= thresh] = color\n",
    "    return result\n",
    "\n",
    "\n",
    "def plot_matrix(sparse_matrix: sparse.csr_matrix, points) -> folium.Map:\n",
    "    fmap = folium.Map(location=[35, -100], zoom_start=6)\n",
    "\n",
    "    colored_matrix = matrix_to_weather_colormap(sparse_matrix=sparse_matrix)\n",
    "\n",
    "    folium.raster_layers.ImageOverlay(\n",
    "        colored_matrix,\n",
    "        pixelated=True,\n",
    "        opacity=0.8,\n",
    "        mercator_project=True,\n",
    "        bounds=BOUNDARIES,\n",
    "    ).add_to(fmap)\n",
    "\n",
    "    # add points list to folium map\n",
    "    for point in points:\n",
    "        folium.CircleMarker(location=(point[0], point[1]),\n",
    "                            radius=2,\n",
    "                            weight=5).add_to(fmap)\n",
    "    return fmap\n",
    "\n",
    "\n",
    "def load_and_show_vil(file_path: str, points) -> folium.Map:\n",
    "    sparse_matrix = sparse.load_npz(file_path)\n",
    "    plot = plot_matrix(sparse_matrix=sparse_matrix, points=points)\n",
    "    return plot\n",
    "\n",
    "\n",
    "def distance(coords_1, coords_2):\n",
    "    return sqrt((coords_1[0] - coords_2[0]) ** 2 + (coords_1[1] - coords_2[1]) ** 2)\n",
    "\n",
    "def distance_fromlist(lst):\n",
    "    all_distance = 0\n",
    "    for i in range(len(lst) - 1):\n",
    "        all_distance += distance(lst[i], lst[i + 1])\n",
    "    return all_distance\n",
    "\n",
    "def get_route(coords_1, coords_2, n):\n",
    "    return [(coords_1[0] + (coords_2[0] - coords_1[0]) * i / n, coords_1[1] + (coords_2[1] - coords_1[1]) * i / n) for i\n",
    "            in range(n)]\n",
    "\n",
    "\n",
    "def all_routes(lst, c=500):\n",
    "    all_points = []\n",
    "    if c < len(lst):\n",
    "        c = len(lst)\n",
    "\n",
    "    distance_list = list()\n",
    "    all_distance = 0\n",
    "    for i in range(len(lst) - 1):\n",
    "        distance_list.append(distance(lst[i], lst[i + 1]))\n",
    "        all_distance += distance(lst[i], lst[i + 1])\n",
    "\n",
    "    for i in range(len(lst) - 2):\n",
    "        n = round(int(c * distance_list[i] / all_distance))\n",
    "        if n == 0:\n",
    "            n = 1\n",
    "        all_points += get_route(lst[i], lst[i + 1], n)\n",
    "\n",
    "    how_many_left = c - len(all_points)\n",
    "    all_points += get_route(lst[-2], lst[-1], how_many_left - 1)\n",
    "    all_points.append(lst[-1])\n",
    "    return all_points\n",
    "\n",
    "\n",
    "def make_map(path, points, c=500):\n",
    "    return load_and_show_vil(path,\n",
    "                             points=all_routes(points, c))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KSEA    21856\n",
       "KIAH    15668\n",
       "KDFW    14476\n",
       "Name: airport, dtype: int64"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"airport\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(df):\n",
    "    df['distance'] = df['waypoints'].apply(lambda x: distance_fromlist(eval(x)))\n",
    "    df['no_of_waypoints'] = df['waypoints'].apply(lambda x: len(eval(x)))\n",
    "    df = df.drop(columns=['timestamp', 'waypoints', 'observation_id'])\n",
    "    df['route_type'] = df['route_type'].map({\"DEPARTURE\": 0, \"ARRIVAL\": 1})\n",
    "    df['timestamp_hour'] = df['timestamp_hour'].str.split(':').apply(lambda row: int(row[0]))\n",
    "    # add year month day column from timestamp_date\n",
    "    df['timestamp_date'] = pd.to_datetime(df['timestamp_date'])\n",
    "    # df['year'] = df['timestamp_date'].dt.year\n",
    "    df['month'] = df['timestamp_date'].dt.month\n",
    "    df['month'].map({1:1, 2:1, 3:2, 4:2, 5:2, 6:3, 7:3, 8:3, 9:4, 10:4, 11:4, 12:1})\n",
    "\n",
    "    # df['day'] = df['timestamp_date'].dt.day\n",
    "    # get day from timestamp_date\n",
    "    df['dayoftheweek'] = df['timestamp_date'].dt.dayofweek\n",
    "    # drop timestamp_date\n",
    "    df = df.drop(columns=['timestamp_date'])\n",
    "    y = df['status']\n",
    "    X = df.drop(columns=['status'])\n",
    "    X = pd.get_dummies(X, columns=['airport', 'timestamp_hour', 'dayoftheweek'])\n",
    "    X = X.drop(columns=['route_id'])\n",
    "    y = y.map({\"CLSD\": 0, \"OPEN\": 1})\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import plot_roc_curve\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.metrics import plot_confusion_matrix \n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate_model(model, X, y):\n",
    "#     scores = cross_val_score(model, X, y, scoring='accuracy', cv=20, n_jobs=-1, error_score='raise')\n",
    "#     return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9381379952825514\n",
      "0.844392523364486\n"
     ]
    }
   ],
   "source": [
    "X, y = pipeline(df)\n",
    "modelDT = DecisionTreeClassifier()\n",
    "modelDT.fit(X, y)\n",
    "from sklearn.metrics import f1_score\n",
    "print(f1_score(modelDT.predict(X), y))\n",
    "\n",
    "X_t, y_t = pipeline(df2)\n",
    "print(f1_score(modelDT.predict(X_t),y_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(modelDT, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observation_id</th>\n",
       "      <th>route_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>status</th>\n",
       "      <th>airport</th>\n",
       "      <th>route_type</th>\n",
       "      <th>waypoints</th>\n",
       "      <th>timestamp_date</th>\n",
       "      <th>timestamp_hour</th>\n",
       "      <th>distance</th>\n",
       "      <th>no_of_waypoints</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [observation_id, route_id, timestamp, status, airport, route_type, waypoints, timestamp_date, timestamp_hour, distance, no_of_waypoints]\n",
       "Index: []"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model_all(route_id, timestamp_date, timestamp_hour, airport, route_type):\n",
    "    df = pd.read_csv('data/statuses/train_data.csv')\n",
    "    df2 = pd.DataFrame()\n",
    "    df2.columns = df.columns\n",
    "    \n",
    "    new_row = {'observation_id':-1, 'route_id':route_id, 'timestamp':timestamp_date + ' ' + timestamp_hour, 'status':'cokolwiek', \n",
    "    'airport': airport, 'route_type': route_type, 'waypoints':df.loc[df['route_id'] == route_id, 'waypoints']}\n",
    "    df2 = df2.append(new_row, ignore_index=True)\n",
    "    X_test, Y_test = pipeline(df2)\n",
    "    print(f1_score(modelDT.predict(X_t),y_t))\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    loaded_model = pickle.load(open('finalized_model.sav', 'rb'))\n",
    "    result = loaded_model.score(X_test, Y_test)\n",
    "    print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7bb082e68b58031467a75daef7f0888ff4f04e807e20698640926b39a7d368f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
